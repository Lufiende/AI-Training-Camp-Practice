# 暑期 AI 实践营总结

## 三、二手车价格估算

### 数据准备

1. **导入和合并数据**：

   使用 `pandas` 导入训练集和测试集数据，合并训练集和测试集，方便后续统一处理。

   ```python
   import pandas as pd
   
   test_data = pd.read_csv('used_car_testB_20200421.csv', sep=' ')
   train_data = pd.read_csv('used_car_train_20200313.csv', sep=' ')
      
   data = pd.concat([train_data, test_data])
   ```

2. **数据预处理**：
   
   替换缺失值和异常值，处理离散数据和连续数据。使用 `One-Hot` 编码处理离散数据，对连续数据进行归一化处理。
   
   ```python
   def oneHotEncode(df, colNames):
       for col in colNames:
           dummies = pd.get_dummies(df[col], prefix=col)
           df = pd.concat([df, dummies],axis=1)
           df.drop([col], axis=1, inplace=True)
       return df
   
   data = data.replace('-', '-1')
   data.notRepairedDamage = data.notRepairedDamage.astype('float32')
   data.loc[data['power']>600,'power'] = 600
   
   for col in config['cate_cols']:
       data[col] = data[col].fillna('-1')
   data = oneHotEncode(data, config['cate_cols'])
   
   for col in config['num_cols']:
       data[col] = data[col].fillna(0)
       data[col] = (data[col]-data[col].min()) / (data[col].max()-data[col].min())
   
   ```
   
3. **数据清洗**：
   
   删除无关列（如 `name` 、`regionCode` 等）。

   ```python
   data.drop(['name', 'regionCode'], axis=1, inplace=True)
   ```
   
4. **分离特征和目标**：
   
   分离训练集和测试集数据，并删除测试集中 `price` 为空的数据，将目标变量 `price` 与特征变量分离，分离出部分数据作为验证集，用于模型评估。
   
   ```python
   test_data = data[pd.isna(data.price)]
   test_data.to_csv('./one_hot_testB.csv')
   
   data.reset_index(inplace=True)
   train_data = data.drop(data[pd.isna(data.price)].index)
   
   train_data.drop(['SaleID'], axis=1, inplace=True)
   train_data = train_data.sample(frac=1)
   
   train_target = train_data['price']
   train_data.drop(['price', 'index'], axis=1, inplace=True)
   
   validation_data = train_data[:10000]
   train_data = train_data[10000:]
   validation_target = train_target[:10000]
   train_target = train_target[10000:]
   ```

### 模型构建

1. **定义神经网络**：
   
   构建一个包含多层线性层、批归一化和激活函数的神经网络，使用 Xavier 初始化方法初始化权重。

   ```python
   from torch import nn, optim
   import torch
   
   class Network(nn.Module):
       def __init__(self, in_dim, hidden_1, hidden_2, hidden_3, hidden_4):
           super().__init__()
           self.layers = nn.Sequential(
               nn.Linear(in_dim, hidden_1),
               nn.BatchNorm1d(hidden_1),
               nn.ReLU(),
               nn.Linear(hidden_1, hidden_2),
               nn.BatchNorm1d(hidden_2),
               nn.ReLU(),
               nn.Linear(hidden_2, hidden_3),
               nn.BatchNorm1d(hidden_3),
               nn.ReLU(),
               nn.Linear(hidden_3, hidden_4),
               nn.BatchNorm1d(hidden_4),
               nn.ReLU(),
               nn.Linear(hidden_4, 1)
           )
   
       def forward(self, x):
           return self.layers(x)
   
   model = Network(train_data.shape[1], 256, 256, 256, 32)
   model.to(config['device'])
   
   for line in model.layers:
       if type(line) == nn.Linear:
           nn.init.xavier_uniform_(line.weight)
   ```
   
2. **数据转换**：
   
   将数据转换为 `tensor` 格式，并移动到 CUDA 。
   
   ```python
   for u in train_data.columns:
       if train_data[u].dtype==bool:
           train_data[u]=train_data[u].astype('int')
   
   for u in validation_data.columns:
       if validation_data[u].dtype==bool:
           validation_data[u]=validation_data[u].astype('int')
   
   train_features = torch.tensor(train_data.values, dtype=torch.float32, device=config['device'])
   train_labels = torch.tensor(train_target.values, dtype=torch.float32, device=config['device'])
   
   validation_features = torch.tensor(validation_data.values, dtype=torch.float32, device=config['device'])
   validation_labels = torch.tensor(validation_target.values, dtype=torch.float32, device=config['device'])
   ```
   
3. **定义损失函数和优化器**：
   
   使用均方误差损失函数 `MSELoss` ，采用 Adam 优化器，并设置学习率。
   
   ```python
   criterion = nn.MSELoss()
   criterion.to(config['device'])
   optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])
   ```

#### 模型训练

1. **训练过程**：
   
   计算训练集和验证集的平均绝对误差 (`MAE`)，并使每个epoch保存模型权重。
   
   ```python
   mae_list = []
   
   for epoch in range(config['epoch']):
       losses = []
       model.train()
       for i in range(0, train_num, config['batch_size']):
           end = i + config['batch_size']
           if i + config['batch_size'] > train_num-1:
               end = train_num-1
           mini_batch = train_features[i: end]
           mini_batch_label = train_labels[i: end]
           pred = model(mini_batch)
           pred = pred.squeeze()
           loss = criterion(pred, mini_batch_label)
   
           if torch.isnan(loss):
               break
           mae = torch.abs(mini_batch_label-pred).sum()/(end-i)
           losses.append(mae.item())
   
           optimizer.zero_grad()
           loss.backward()
           optimizer.step()
   
       model.eval()
       pred = model(validation_features)
       validation_mae = torch.abs(validation_labels-pred.squeeze()).sum().item()/validation_num
   
       mae_list.append((sum(losses)/len(losses), validation_mae))
   
       print(f"epoch:{epoch + 1} MAE: {sum(losses)/len(losses)}, Validation_MAE: {validation_mae}")
       torch.save(model, 'model.pth')
   ```
   
2. **绘制训练曲线**：
   
   绘制训练集和验证集的损失曲线，观察模型拟合情况。
   
   ```py
   x = np.arange(0, config['epoch'])
   y1, y2 = zip(*mae_list)
   plt.plot(x, y1, label='train')
   plt.plot(x, y2, label='valid')
   plt.legend()
   plt.show()

#### 模型预测

1. **加载模型**：
   
   加载训练好的模型权重。
   
   ```python
   import pandas as pd
   import torch
   
   model = torch.load('model.pth', map_location=config['device'])
   ```
   
2. **处理测试数据**：
   
   对测试数据进行预处理，使其格式与训练数据一致。
   
   ```python
   data = pd.read_csv('./one_hot_testB.csv')
   data = data.drop(columns=['Unnamed: 0', 'price'])
   test = data.drop(columns='SaleID')
   
   for u in test.columns:
       if test[u].dtype==bool:
           test[u]=test[u].astype('int')
   
   test = torch.tensor(test.values, dtype=torch.float32)
   ```
   
3. **生成预测结果**：
   
   使用训练好的模型对测试数据进行预测，并将预测结果保存为CSV文件。
   
   ```python
   pred = model(test)
   price = pd.DataFrame(pred.detach().cpu().numpy(), columns=['price'])
   res = pd.concat([data.SaleID, price], axis=1)
   res.to_csv('output.csv', index=False)
   ```
